{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beer_Review_ANN Regression",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpdsec/DataScience-Python/blob/master/Beer_Review_ANN_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSwdweV3OdJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNB0vrXdOHqx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fea99beb-3160-45eb-d1f4-a6da4fe768db"
      },
      "source": [
        "# loading the dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Input/rann_train.csv')\n",
        "dataset.columns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['review/appearance', 'review/aroma', 'review/overall', 'review/palate',\n",
              "       'review/taste'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTYP-QN4i__7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = ['review/appearance', 'review/aroma', 'review/palate',\n",
        "       'review/taste']\n",
        "X = dataset[features]\n",
        "Y = dataset['review/overall']\n",
        "X, x, Y, y = train_test_split(X,Y, test_size = 0.4)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV8dU4I-uHMZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "3784d7e8-98aa-49cb-a522-9bf30e2765e6"
      },
      "source": [
        "X.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 22500 entries, 7587 to 27545\n",
            "Data columns (total 4 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   review/appearance  22500 non-null  float64\n",
            " 1   review/aroma       22500 non-null  float64\n",
            " 2   review/palate      22500 non-null  float64\n",
            " 3   review/taste       22500 non-null  float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 878.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nYuEZ8vuNBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "e0f01e2c-6d13-4414-b551-dbdfe2a3a3bb"
      },
      "source": [
        "X.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review/appearance</th>\n",
              "      <th>review/aroma</th>\n",
              "      <th>review/palate</th>\n",
              "      <th>review/taste</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>22500.000000</td>\n",
              "      <td>22500.000000</td>\n",
              "      <td>22500.000000</td>\n",
              "      <td>22500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.903578</td>\n",
              "      <td>3.874511</td>\n",
              "      <td>3.858800</td>\n",
              "      <td>3.926822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.584785</td>\n",
              "      <td>0.680078</td>\n",
              "      <td>0.664893</td>\n",
              "      <td>0.713731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       review/appearance  review/aroma  review/palate  review/taste\n",
              "count       22500.000000  22500.000000   22500.000000  22500.000000\n",
              "mean            3.903578      3.874511       3.858800      3.926822\n",
              "std             0.584785      0.680078       0.664893      0.713731\n",
              "min             1.000000      1.000000       1.000000      1.000000\n",
              "25%             3.500000      3.500000       3.500000      3.500000\n",
              "50%             4.000000      4.000000       4.000000      4.000000\n",
              "75%             4.500000      4.500000       4.500000      4.500000\n",
              "max             5.000000      5.000000       5.000000      5.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD77mtCE5ltH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimiser\n",
        "opt = tf.keras.optimizers.Adam(0.01)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOiN3hFXPBRR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "7c8f5488-4a20-4e34-80d4-483330055140"
      },
      "source": [
        "# Build the model\n",
        "rann = Sequential()\n",
        "# 1st Layer\n",
        "rann.add(Dense(64, input_shape=(4,), activation='relu'))\n",
        "# 2nd Layer\n",
        "rann.add(Dense(16, activation='relu'))\n",
        "# Output Layer\n",
        "rann.add(Dense(1))\n",
        "# Compile\n",
        "rann.compile(optimizer=opt, loss='mse')\n",
        "# summary\n",
        "rann.summary()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                320       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,377\n",
            "Trainable params: 1,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ja7vQTPPjrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c9ebe7d-d04b-49a7-c844-e9c1f89419d6"
      },
      "source": [
        "# fit\n",
        "\n",
        "r = rann.fit(X, Y,\n",
        "             batch_size = 64, \n",
        "             #validation_data =(x,y), \n",
        "             epochs=100, \n",
        "             shuffle = True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.2422\n",
            "Epoch 2/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1744\n",
            "Epoch 3/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1788\n",
            "Epoch 4/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1767\n",
            "Epoch 5/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1751\n",
            "Epoch 6/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1725\n",
            "Epoch 7/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1765\n",
            "Epoch 8/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1727\n",
            "Epoch 9/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1752\n",
            "Epoch 10/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1757\n",
            "Epoch 11/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1729\n",
            "Epoch 12/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1748\n",
            "Epoch 13/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1745\n",
            "Epoch 14/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1741\n",
            "Epoch 15/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1718\n",
            "Epoch 16/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1734\n",
            "Epoch 17/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1767\n",
            "Epoch 18/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1729\n",
            "Epoch 19/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1725\n",
            "Epoch 20/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1761\n",
            "Epoch 21/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1729\n",
            "Epoch 22/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1717\n",
            "Epoch 23/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1716\n",
            "Epoch 24/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1746\n",
            "Epoch 25/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1706\n",
            "Epoch 26/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1710\n",
            "Epoch 27/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1722\n",
            "Epoch 28/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1728\n",
            "Epoch 29/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1704\n",
            "Epoch 30/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1702\n",
            "Epoch 31/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1700\n",
            "Epoch 32/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1694\n",
            "Epoch 33/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1694\n",
            "Epoch 34/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1700\n",
            "Epoch 35/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1714\n",
            "Epoch 36/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1718\n",
            "Epoch 37/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1700\n",
            "Epoch 38/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1697\n",
            "Epoch 39/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1708\n",
            "Epoch 40/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1700\n",
            "Epoch 41/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1704\n",
            "Epoch 42/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1710\n",
            "Epoch 43/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1703\n",
            "Epoch 44/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1700\n",
            "Epoch 45/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1696\n",
            "Epoch 46/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1691\n",
            "Epoch 47/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1696\n",
            "Epoch 48/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1707\n",
            "Epoch 49/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1704\n",
            "Epoch 50/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1694\n",
            "Epoch 51/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1684\n",
            "Epoch 52/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1699\n",
            "Epoch 53/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1713\n",
            "Epoch 54/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1692\n",
            "Epoch 55/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1697\n",
            "Epoch 56/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1693\n",
            "Epoch 57/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1704\n",
            "Epoch 58/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1701\n",
            "Epoch 59/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1690\n",
            "Epoch 60/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1692\n",
            "Epoch 61/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1687\n",
            "Epoch 62/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1693\n",
            "Epoch 63/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1689\n",
            "Epoch 64/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1703\n",
            "Epoch 65/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1691\n",
            "Epoch 66/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1686\n",
            "Epoch 67/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1694\n",
            "Epoch 68/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1703\n",
            "Epoch 69/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1689\n",
            "Epoch 70/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1709\n",
            "Epoch 71/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1683\n",
            "Epoch 72/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1690\n",
            "Epoch 73/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1703\n",
            "Epoch 74/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1688\n",
            "Epoch 75/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1699\n",
            "Epoch 76/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1688\n",
            "Epoch 77/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1684\n",
            "Epoch 78/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1693\n",
            "Epoch 79/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1685\n",
            "Epoch 80/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1720\n",
            "Epoch 81/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1688\n",
            "Epoch 82/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1704\n",
            "Epoch 83/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1696\n",
            "Epoch 84/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1684\n",
            "Epoch 85/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1690\n",
            "Epoch 86/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1691\n",
            "Epoch 87/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1686\n",
            "Epoch 88/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1699\n",
            "Epoch 89/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1694\n",
            "Epoch 90/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1685\n",
            "Epoch 91/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1684\n",
            "Epoch 92/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1695\n",
            "Epoch 93/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1693\n",
            "Epoch 94/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1689\n",
            "Epoch 95/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1702\n",
            "Epoch 96/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1713\n",
            "Epoch 97/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1684\n",
            "Epoch 98/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1689\n",
            "Epoch 99/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1694\n",
            "Epoch 100/100\n",
            "352/352 [==============================] - 1s 3ms/step - loss: 0.1692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pKxxsJ1P-me",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "7606efe8-e882-40a7-c3c0-804450ec252b"
      },
      "source": [
        "# Plot the loss\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(r.history['loss'], color='b', label=\"Training loss\")\n",
        "#plt.plot(r.history['val_loss'], color='r', label=\"validation loss\")\n",
        "plt.legend()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1170091208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8UxYh-e_Yv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce9f31ee-8318-4b86-cffa-24c268d63be9"
      },
      "source": [
        "# prediction\n",
        "y_pred = rann.predict(x)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "print(mse)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.16685920401198415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r7RmnhFJnBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "List = []\n",
        "for i in range(len(y_pred)):\n",
        "  List.append(y_pred[i][0])\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwQsmZ-IAU4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "009ec816-2fdf-4e95-8d1b-4404039e978b"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df[\"Y_Predictions\"] = List\n",
        "df[\"Y\"] = y.to_list()\n",
        "df.head(50)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_Predictions</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.586390</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.981476</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.670710</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.203067</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.324602</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.808635</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.636017</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.257906</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4.022043</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.433716</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.796121</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.433716</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.865401</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.776580</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.903099</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.819743</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4.367502</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4.286904</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3.768901</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4.019341</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>4.247067</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4.364800</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>4.468794</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>4.022043</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3.054912</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3.638720</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>4.019341</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3.433716</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.737470</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3.755250</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>3.981476</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>3.981476</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>4.326936</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2.770445</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>4.281499</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>4.203067</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>4.120548</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>4.286904</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>3.978774</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3.865401</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>4.364800</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>4.203067</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4.000766</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>4.019341</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>3.817040</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2.649852</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>4.286904</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>4.162524</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>3.252641</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>4.324602</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Y_Predictions    Y\n",
              "0        4.586390  5.0\n",
              "1        3.981476  4.5\n",
              "2        4.670710  4.5\n",
              "3        4.203067  4.0\n",
              "4        4.324602  5.0\n",
              "5        2.808635  2.5\n",
              "6        3.636017  3.5\n",
              "7        3.257906  4.0\n",
              "8        4.022043  4.0\n",
              "9        3.433716  3.5\n",
              "10       2.796121  3.0\n",
              "11       3.433716  3.5\n",
              "12       3.865401  4.5\n",
              "13       3.776580  4.0\n",
              "14       3.903099  4.0\n",
              "15       3.819743  4.0\n",
              "16       4.367502  4.5\n",
              "17       4.286904  5.0\n",
              "18       3.768901  4.0\n",
              "19       4.019341  4.0\n",
              "20       4.247067  4.0\n",
              "21       4.364800  4.5\n",
              "22       4.468794  4.5\n",
              "23       4.022043  3.5\n",
              "24       3.054912  3.5\n",
              "25       3.638720  3.5\n",
              "26       4.019341  4.0\n",
              "27       3.433716  3.5\n",
              "28       3.737470  4.0\n",
              "29       3.755250  4.0\n",
              "30       3.981476  4.0\n",
              "31       3.981476  4.0\n",
              "32       4.326936  4.5\n",
              "33       2.770445  4.0\n",
              "34       4.281499  4.5\n",
              "35       4.203067  4.5\n",
              "36       4.120548  4.0\n",
              "37       4.286904  4.0\n",
              "38       3.978774  4.5\n",
              "39       3.865401  4.5\n",
              "40       4.364800  4.5\n",
              "41       4.203067  4.0\n",
              "42       4.000766  3.5\n",
              "43       4.019341  4.0\n",
              "44       3.817040  3.5\n",
              "45       2.649852  2.5\n",
              "46       4.286904  4.5\n",
              "47       4.162524  4.0\n",
              "48       3.252641  3.5\n",
              "49       4.324602  4.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e22b3EOvFLyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "84b4f1bc-8282-4608-fd2b-f44d84594562"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Y_Predictions</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15000.000000</td>\n",
              "      <td>15000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.857377</td>\n",
              "      <td>3.882633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.549057</td>\n",
              "      <td>0.703900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.297182</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.638720</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.981476</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.203067</td>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.748245</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Y_Predictions             Y\n",
              "count   15000.000000  15000.000000\n",
              "mean        3.857377      3.882633\n",
              "std         0.549057      0.703900\n",
              "min         1.297182      0.000000\n",
              "25%         3.638720      3.500000\n",
              "50%         3.981476      4.000000\n",
              "75%         4.203067      4.500000\n",
              "max         4.748245      5.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}