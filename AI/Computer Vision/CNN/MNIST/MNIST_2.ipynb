{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJFItf1FQFF7"
      },
      "source": [
        "### **1. Importing Libraries**\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT5CUoUogPlA"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import save_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P1M6AcOQjjE"
      },
      "source": [
        "### **2. Loading & Processing Data**\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxVMpBuagaUC"
      },
      "source": [
        "def data_load():\n",
        "  (X_train, y_train),(X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  X_train = X_train/255.0\n",
        "  X_test = X_test/255.0\n",
        "  X_train = X_train[..., tf.newaxis].astype('float32')\n",
        "  X_test = X_test[..., tf.newaxis].astype('float32')\n",
        "  return X_train, y_train, X_test, y_test\n",
        "X_train, y_train, X_test, y_test =data_load()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ8HIyqVVE4X",
        "outputId": "c6d1791f-5062-46ab-d71d-ee3fb3a4f9c9"
      },
      "source": [
        "print(X_train.shape)\r\n",
        "print(X_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PAbxoZVYMC-"
      },
      "source": [
        "## Batching and shuffling Data\r\n",
        "\r\n",
        "def data_batch(X_train, y_train, X_test, y_test):\r\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices(\r\n",
        "    (X_train, y_train)).shuffle(10000).batch(32)\r\n",
        "  test_ds = tf.data.Dataset.from_tensor_slices(\r\n",
        "      (X_test, y_test)).shuffle(10000).batch(32)\r\n",
        "  return train_ds, test_ds\r\n",
        "train_ds,test_ds = data_batch(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD6Ay1NBRxQU"
      },
      "source": [
        "### **3. Creating Class with tf.keras subclass Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ht5UiifePor"
      },
      "source": [
        "\r\n",
        "class MyModel(Model):\r\n",
        "  def __init__(self):\r\n",
        "    super().__init__()\r\n",
        "    self.conv1 = Conv2D(32,3, activation='relu')\r\n",
        "    self.conv2 = Conv2D(64,3, activation='relu')\r\n",
        "    self.flatten = Flatten()\r\n",
        "    self.dropout = Dropout(0.25)\r\n",
        "    self.maxpool = MaxPooling2D(2,2)\r\n",
        "    self.d1 = Dense(1024, activation='relu')\r\n",
        "    self.d2 = Dense(128, activation='relu')\r\n",
        "    self.d3 = Dense(10)\r\n",
        "  def call(self, x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.maxpool(x)\r\n",
        "    x = self.conv2(x)\r\n",
        "    x = self.maxpool(x)\r\n",
        "    x = self.flatten(x)\r\n",
        "    x = self.d1(x)\r\n",
        "    x = self.dropout(x)\r\n",
        "    x = self.d2(x)\r\n",
        "    return self.d3(x)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-z7giicjns8"
      },
      "source": [
        "# creating instance of model\r\n",
        "model = MyModel()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fak0KjtASMdd"
      },
      "source": [
        "### **4. Optimizer and loss Function** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv2EtPA2j6nn"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "Optimiser = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJDUJLAXSoZn"
      },
      "source": [
        "### **5. Metrics For Loss and Acuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZV_OLFelKHN"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\r\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\r\n",
        "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\r\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk8eJelPTHA3"
      },
      "source": [
        "### **6. Function for training and Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcbvePZavERI"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(images, labels):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    prediction = model(images, training=True)\r\n",
        "    loss = loss_object(labels,prediction)\r\n",
        "  gradient = tape.gradient(loss, model.trainable_variables)\r\n",
        "  Optimiser.apply_gradients(zip(gradient, model.trainable_variables))\r\n",
        "  train_loss(loss)\r\n",
        "  train_accuracy(labels, prediction)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHkF3irCnJ4e"
      },
      "source": [
        "@tf.function\r\n",
        "def test_step(images, labels):\r\n",
        "  prediction = model(images, training = False)\r\n",
        "  t_loss = loss_object(labels, prediction)\r\n",
        "  test_loss(t_loss)\r\n",
        "  test_accuracy(labels, prediction)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aroHrgIrTYSN"
      },
      "source": [
        "### **7. Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx6KtgRvngNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f417612-d7cd-4e9d-c94a-7af1ebf420b9"
      },
      "source": [
        "EPOCHS = 5\r\n",
        "min_Loss = 0\r\n",
        "min_Accuracy = 0\r\n",
        "\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "  train_loss.reset_states()\r\n",
        "  train_accuracy.reset_states()\r\n",
        "  test_loss.reset_states()\r\n",
        "  test_accuracy.reset_states()\r\n",
        "\r\n",
        "  for images, labels in train_ds:\r\n",
        "    train_step(images, labels)\r\n",
        "  for test_images, test_labels in test_ds:\r\n",
        "    test_step(test_images, test_labels)\r\n",
        "\r\n",
        "  print(\r\n",
        "      f'Epoch {epoch + 1}, '\r\n",
        "      f'Loss: {train_loss.result()}, '\r\n",
        "      f'Accuracy: {train_accuracy.result()*100}, '\r\n",
        "      f'Test Loss: {test_loss.result()}, '\r\n",
        "      f'Test Accuracy: {test_accuracy.result()*100}'\r\n",
        "  )\r\n",
        "\r\n",
        "  ### Implementing  CallBack\r\n",
        "\r\n",
        "  if epoch==0:\r\n",
        "    min_Loss = train_loss.result()\r\n",
        "    min_Accuracy = train_accuracy.result()*100\r\n",
        "  if (min_Loss>train_loss.result()):\r\n",
        "    if (min_Accuracy <= train_accuracy.result()*100) :\r\n",
        "      min_Loss = train_loss.result()\r\n",
        "      min_Accuracy = ( train_accuracy.result()*100)\r\n",
        "      #path = 'BS_'+ str(epoch + 1)+'_'+ str(min_Loss)+'_'+str(min_Accuracy) +'.h5'\r\n",
        "      print(f\"Saving Best Model {epoch+1}\")\r\n",
        "      path = f'/content/drive/MyDrive/Colab Notebooks/Model/BS_{epoch + 1}_{train_loss.result()}_{train_accuracy.result()*100}.h5'  \r\n",
        "\r\n",
        "      model.save_weights(path)                            # Saving Model To drive\r\n",
        "      #tf.keras.models.save_model(model, path, overwrite=True, include_optimizer=True, save_format='tf',\r\n",
        "      #                           signatures=None, options=None, save_traces=True)\r\n",
        " "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.11896396428346634, Accuracy: 96.3133316040039, Test Loss: 0.04206095635890961, Test Accuracy: 98.61000061035156\n",
            "Epoch 2, Loss: 0.044934533536434174, Accuracy: 98.6050033569336, Test Loss: 0.04038241133093834, Test Accuracy: 98.75\n",
            "Saving Best Model 2\n",
            "Epoch 3, Loss: 0.03253794461488724, Accuracy: 99.0250015258789, Test Loss: 0.02983248420059681, Test Accuracy: 99.11000061035156\n",
            "Saving Best Model 3\n",
            "Epoch 4, Loss: 0.0240387674421072, Accuracy: 99.24333190917969, Test Loss: 0.04142998903989792, Test Accuracy: 98.79999542236328\n",
            "Saving Best Model 4\n",
            "Epoch 5, Loss: 0.0192902609705925, Accuracy: 99.4183349609375, Test Loss: 0.03751206770539284, Test Accuracy: 99.04000091552734\n",
            "Saving Best Model 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KRd5eAut-GR"
      },
      "source": [
        "\r\n",
        "\r\n",
        "\r\n",
        "*   Template From TensorFlow 2 quickstart for experts\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    }
  ]
}